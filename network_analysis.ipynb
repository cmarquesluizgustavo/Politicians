{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBasicInfo(G):\n",
    "    nodes = G.number_of_nodes()\n",
    "    edges = G.number_of_edges()\n",
    "    density = nx.density(G)\n",
    "    try:\n",
    "        biggest_cc = max(nx.connected_components(G), key=len)\n",
    "        biggest_cc = G.subgraph(biggest_cc)\n",
    "        diameter = nx.diameter(biggest_cc)\n",
    "\n",
    "    except:\n",
    "        diameter = None\n",
    "    avg_degree = sum([d for n, d in G.degree()]) / nodes\n",
    "    clustering_distribution = [c for n, c in nx.clustering(G).items()]\n",
    "    average_clustering = sum(clustering_distribution) / nodes\n",
    "    global_clustering = nx.transitivity(G)\n",
    "    max_degree = max([d for n, d in G.degree()])\n",
    "    min_degree = min([d for n, d in G.degree()])\n",
    "    zero_degree = sum([1 for n, d in G.degree() if d == 0]) / nodes\n",
    "    degree_distribution = [d for n, d in G.degree()]\n",
    "    node_with_max_degree = [n for n, d in G.degree() if d == max_degree]\n",
    "    \n",
    "    return nodes, edges, diameter, density, avg_degree, average_clustering, \\\n",
    "           global_clustering, \\\n",
    "           max_degree, min_degree, zero_degree, degree_distribution, \\\n",
    "           clustering_distribution, node_with_max_degree\n",
    "           \n",
    "\n",
    "def printBasicInfo(info_list):\n",
    "    print('Number of nodes: ', info_list[0])\n",
    "    print('Number of edges: ', info_list[1])\n",
    "    print('Diameter: ', info_list[2])\n",
    "    print('Density: ', info_list[3])\n",
    "    print('Average degree: ', info_list[4])\n",
    "    print('Average clustering: ', info_list[5])\n",
    "    print('Global clustering: ', info_list[6])\n",
    "    print('Max degree: ', info_list[7])\n",
    "    print('Min degree: ', info_list[8])\n",
    "    print('Zero degree: ', info_list[9])\n",
    "    print('Node with max degree: ', info_list[12])\n",
    "\n",
    "\n",
    "def plot_CCDF(data: list, title: str, xlabel: str, ylabel: str, save_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot the CCDF of a given array.\n",
    "    \"\"\"\n",
    "    ccdf = CCDF(data)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(ccdf) + 1), ccdf, 'o', markersize=3)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "def CCDF(data: list) -> list:\n",
    "    \"\"\"\n",
    "    Calculate the CCDF of a given array.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    data.sort()\n",
    "    s = data.sum()\n",
    "    cdf = data.cumsum(0) / s\n",
    "    ccdf = 1 - cdf\n",
    "    return ccdf\n",
    "\n",
    "def modularidadePorAtributo(G, atributo):\n",
    "    node_atributes = nx.get_node_attributes(G, atributo)\n",
    "    partitions = {}\n",
    "    for key, value in node_atributes.items():\n",
    "        partitions[value] = partitions.get(value, []) + [key]\n",
    "\n",
    "    # remove the unvisited nodes from G\n",
    "    partitions = [set(partition) for partition in partitions.values()]\n",
    "    modularity = nx.algorithms.community.modularity(G, partitions)\n",
    "    return modularity\n",
    "\n",
    "def removeWeirdNodes(G):\n",
    "    node_atributes = nx.get_node_attributes(G, 'age')\n",
    "    partitions = {}\n",
    "    visited_nodes = []\n",
    "    for key, value in node_atributes.items():\n",
    "        partitions[value] = partitions.get(value, []) + [key]\n",
    "        visited_nodes.append(key)\n",
    "\n",
    "    # remove the unvisited nodes from G\n",
    "    G.remove_nodes_from(set(G.nodes()) - set(visited_nodes))\n",
    "    return G\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotMetricEvolutionOverTime(infos_years):\n",
    "    marked_years = [2022, 2018, 2014, 2010, 2006, 2002, 1998]\n",
    "    metric_names = ['Number of nodes',\n",
    "                    'Number of edges',\n",
    "                    'Diameter',\n",
    "                    'Density',\n",
    "                    'Average degree',\n",
    "                    'Average clustering',\n",
    "                    'Global clustering',\n",
    "                    'Max degree',\n",
    "                    'Min degree',\n",
    "                    'Zero degree',\n",
    "                    'Node with max degree']\n",
    "    years = list(range(2000, 2024))\n",
    "    for i in range(len(metric_names)):\n",
    "        metric = []\n",
    "        for year in years:\n",
    "            metric.append(infos_years[str(year)][i])\n",
    "\n",
    "        # Make each plot from scratch, years as x label, save\n",
    "        plt.figure()\n",
    "        plt.plot(years, metric, label=metric_names[i], marker='o')\n",
    "        \n",
    "        # Add red vertical lines at marked years without legend\n",
    "        for marked_year in [2022, 2018, 2014, 2010, 2006, 2002, 1998]:\n",
    "            plt.axvline(x=marked_year, color='red', linestyle='--')\n",
    "        \n",
    "        plt.title(metric_names[i])\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel(metric_names[i])\n",
    "        plt.savefig(f'plots/{metric_names[i]}.png')\n",
    "\n",
    "\n",
    "\n",
    "def plotMetricEvolutionOverTime2(infos_terms):\n",
    "    metric_names = ['Number of nodes',\n",
    "                    'Number of edges',\n",
    "                    'Diameter',\n",
    "                    'Density',\n",
    "                    'Average degree',\n",
    "                    'Average clustering',\n",
    "                    'Global clustering',\n",
    "                    'Max degree',\n",
    "                    'Min degree',\n",
    "                    'Zero degree',\n",
    "                    'Node with max degree']\n",
    "    terms = list(range(51, 58))\n",
    "    for i in range(len(metric_names)):\n",
    "        metric = []\n",
    "        for term in terms:\n",
    "            metric.append(infos_terms[str(term)][i])\n",
    "\n",
    "        # Make each plot from scratch, years as x label, save\n",
    "        plt.figure()\n",
    "        plt.plot(terms, metric, label=metric_names[i], marker='o')\n",
    "        plt.title(metric_names[i])\n",
    "        plt.xlabel('Term')\n",
    "        plt.ylabel(metric_names[i])\n",
    "        plt.savefig(f'plots/{metric_names[i]}_terms.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netwoks_folder = 'data/networks/'\n",
    "networks = os.listdir(netwoks_folder)\n",
    "networks = [netwoks_folder + network for network in networks]\n",
    "networks = [network for network in networks if network.endswith('.gpickle')]\n",
    "infos_years = {}\n",
    "infos_terms = {}\n",
    "modularidade_por_atributo_ano = {}\n",
    "modularidade_por_atributo_terms = {}\n",
    "for network in networks:\n",
    "    print(network)\n",
    "    with open(network, 'rb') as f:\n",
    "        G = pickle.load(f)\n",
    "    try:\n",
    "        G = removeWeirdNodes(G)\n",
    "        info_list = getBasicInfo(G)\n",
    "    except Exception as e:\n",
    "        print('Error in network: ', network)\n",
    "        print(e)\n",
    "        break\n",
    "    printBasicInfo(info_list)\n",
    "    # plot_CCDF(info_list[10], 'Degree distribution', 'Degree', 'CCDF', 'plots/degree_distribution.png')\n",
    "\n",
    "    atributos = ['education', 'gender','siglaUf', 'siglaPartido', 'region', 'occupation', 'marital_status', 'ethnicity', 'age']\n",
    "    modularidade_por_atributo = {}\n",
    "    for atributo in atributos:\n",
    "        modularidade_por_atributo[atributo] = modularidadePorAtributo(G, atributo)\n",
    "\n",
    "    if '20' in network:\n",
    "        year = network.split('network.gpickle')[0].split('/')[-1]\n",
    "        infos_years[year] = info_list\n",
    "        modularidade_por_atributo_ano[year] = modularidade_por_atributo\n",
    "    else:\n",
    "        term = network.split('network.gpickle')[0].split('/')[-1]\n",
    "        infos_terms[term] = info_list\n",
    "        modularidade_por_atributo_terms[term] = modularidade_por_atributo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMetricEvolutionOverTime2(infos_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotModularityOverTime(modularidade_por_atributo_ano):\n",
    "    atributos_list = [\n",
    "        'education','gender','siglaUf','siglaPartido','region','occupation','marital_status','ethnicity','age'\n",
    "    ]\n",
    "    years = list(range(2000, 2024))\n",
    "    for atributo in atributos_list:\n",
    "        metric = []\n",
    "        for year in years:\n",
    "            metric.append(modularidade_por_atributo_ano[str(year)][atributo])\n",
    "\n",
    "        for marked_year in [2022, 2018, 2014, 2010, 2006, 2002]:\n",
    "            plt.axvline(x=marked_year, color='red', linestyle='--')\n",
    "        \n",
    "        for marked_year in [2020, 2016, 2012, 2008, 2004, 2000]:\n",
    "            plt.axvline(x=marked_year, color='green', linestyle='--')\n",
    "        \n",
    "\n",
    "        # Make each plot from scratch, years as x label, save\n",
    "        plt.figure()\n",
    "        plt.plot(years, metric, label=atributo, marker='o')\n",
    "        plt.title(atributo)\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel(atributo)\n",
    "\n",
    "        plt.savefig(f'plots/modularity/{atributo}_modularity.png')\n",
    "def plotModularityOverTime2(modularidade_por_atributo_terms):\n",
    "    atributos_list = [\n",
    "        'education','gender','siglaUf','siglaPartido','region','occupation','marital_status','ethnicity','age'\n",
    "    ]\n",
    "    terms = list(range(51, 58))\n",
    "\n",
    "    for atributo in atributos_list:\n",
    "        metric = []\n",
    "        for term in terms:\n",
    "            metric.append(modularidade_por_atributo_terms[str(term)][atributo])\n",
    "\n",
    "        # Make each plot from scratch, years as x label, save\n",
    "        plt.figure()\n",
    "        plt.plot(terms, metric, label=atributo, marker='o')\n",
    "        plt.title(atributo)\n",
    "        plt.xlabel('Term')\n",
    "        plt.ylabel(atributo)\n",
    "        plt.xticks(terms, rotation=45)\n",
    "\n",
    "        plt.savefig(f'plots/modularity/{atributo}_modularity_terms.png')\n",
    "\n",
    "plotModularityOverTime(modularidade_por_atributo_ano)\n",
    "plotModularityOverTime2(modularidade_por_atributo_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_pagerank(G):\n",
    "    '''\n",
    "    Return the most relevant congressperson of a given network\n",
    "    '''\n",
    "    pagerank = nx.pagerank(G)\n",
    "    highest_pagerank = max(pagerank, key=pagerank.get)\n",
    "    degree = dict(G.degree())\n",
    "    degree_of_most_relevant = degree[highest_pagerank]\n",
    "\n",
    "    return highest_pagerank, degree_of_most_relevant\n",
    "\n",
    "def highest_degree_function(G):\n",
    "    '''\n",
    "    Return the most relevant congressperson of a given network\n",
    "    '''\n",
    "    degree = dict(G.degree())\n",
    "    highest_degree = max(degree, key=degree.get)\n",
    "    degree_of_most_relevant = degree[highest_degree]\n",
    "    return highest_degree, degree_of_most_relevant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank_year = {}\n",
    "pagerank_term = {}\n",
    "degree_term = {}\n",
    "degree_year = {}\n",
    "netwoks_folder = 'data/networks/'\n",
    "networks = os.listdir(netwoks_folder)\n",
    "networks = [netwoks_folder + network for network in networks]\n",
    "networks = [network for network in networks if network.endswith('.gpickle')]\n",
    "\n",
    "for network in networks:\n",
    "    print(network)\n",
    "    with open(network, 'rb') as f:\n",
    "        G = pickle.load(f)\n",
    "\n",
    "    if '20' in network:\n",
    "        year = network.split('network.gpickle')[0].split('/')[-1]\n",
    "        pagerank_year[year] = highest_pagerank(G)\n",
    "        degree_year[year] = highest_degree_function(G)\n",
    "    else:\n",
    "        term = network.split('network.gpickle')[0].split('/')[-1]\n",
    "        pagerank_term[term] = highest_pagerank(G)\n",
    "        degree_term[term] = highest_degree_function(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "congresspersons = 'data/congresspeople/enriched_congresspeople.csv'\n",
    "congresspersons_df = pd.read_csv(congresspersons)\n",
    "congresspersons_df = congresspersons_df[['id', 'nomeEleitoral']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_page_rank = pd.DataFrame()\n",
    "for year in pagerank_year.keys():\n",
    "    nome = congresspersons_df[congresspersons_df['id'] == pagerank_year[year][0]]['nomeEleitoral'].unique()[0]\n",
    "    nome = ' '.join([subnome.capitalize() for subnome in nome.split(' ')])\n",
    "    df = pd.DataFrame({\n",
    "        'year': [year],\n",
    "        'nome': [nome],\n",
    "        'degree': [pagerank_year[year][1]]\n",
    "    })\n",
    "    df_page_rank = pd.concat([\n",
    "        df_page_rank, \n",
    "        df\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_degree = pd.DataFrame()\n",
    "for year in degree_year.keys():\n",
    "    nome = congresspersons_df[congresspersons_df['id'] == degree_year[year][0]]['nomeEleitoral'].unique()[0]\n",
    "    nome = ' '.join([subnome.capitalize() for subnome in nome.split(' ')])\n",
    "    df = pd.DataFrame({\n",
    "        'year': [year],\n",
    "        'nome': [nome],\n",
    "        'degree': [degree_year[year][1]]\n",
    "    })\n",
    "    df_degree = pd.concat([\n",
    "        df_degree,\n",
    "        df \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_page_rank.sort_values(by=['year'], inplace=True)\n",
    "df_degree.sort_values(by=['year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_degree.to_csv('data/results/degree.csv', index=False)\n",
    "df_page_rank.to_csv('data/results/pagerank.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
